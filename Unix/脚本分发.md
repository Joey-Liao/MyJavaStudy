**1****）scp****（secure copy****）安全拷贝**

（1）scp定义

scp可以实现服务器与服务器之间的数据拷贝。（from server1 to server2）

​    （2）基本语法

```
scp   -r    $pdir/$fname       $user@$host:$pdir/$fname
```

命令  递归   要拷贝的文件路径/名称  目的地用户@主机:目的地路径/名称

（3）案例实操

Ø 前提：在hadoop102、hadoop103、hadoop104都已经创建好的/opt/module、      /opt/software两个目录，并且已经把这两个目录修改为atguigu:atguigu

```
[atguigu@hadoop102 ~]$ sudo chown atguigu:atguigu -R /opt/module
```

（a）在hadoop102上，将hadoop102中/opt/module/jdk1.8.0_212目录拷贝到hadoop103上。

```
[atguigu@hadoop102 ~]$ scp -r /opt/module/jdk1.8.0_212 atguigu@hadoop103:/opt/module
```

（b）在hadoop103上，将hadoop102中/opt/module/hadoop-3.1.3目录拷贝到hadoop103上。

```
[atguigu@hadoop103 ~]$ scp -r atguigu@hadoop102:/opt/module/hadoop-3.1.3 /opt/module/
```

（c）在hadoop103上操作，将hadoop102中/opt/module目录下所有目录拷贝到hadoop104上。

```
[atguigu@hadoop103 opt]$ scp -r atguigu@hadoop102:/opt/module/* atguigu@hadoop104:/opt/module
```

**2****）rsync****远程同步工具**

rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。

rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。

​    （1）基本语法

```
rsync   -av    $pdir/$fname       $user@$host:$pdir/$fname
```

命令  选项参数  要拷贝的文件路径/名称  目的地用户@主机:目的地路径/名称

​     选项参数说明

| 选项 | 功能         |
| ---- | ------------ |
| -a   | 归档拷贝     |
| -v   | 显示复制过程 |

（2）案例实操

​    （a）删除hadoop103中/opt/module/hadoop-3.1.3/wcinput

```
[atguigu@hadoop103 hadoop-3.1.3]$ rm -rf wcinput/
```

​    （b）同步hadoop102中的/opt/module/hadoop-3.1.3到hadoop103

```
[atguigu@hadoop102 module]$ rsync -av hadoop-3.1.3/ atguigu@hadoop103:/opt/module/hadoop-3.1.3/
```

**3****）xsync****集群分发脚本**

（1）需求：循环复制文件到所有节点的相同目录下

​    （2）需求分析：

（a）rsync命令原始拷贝：

```
rsync -av   /opt/module     atguigu@hadoop103:/opt/
```

（b）期望脚本：

xsync要同步的文件名称

（c）期望脚本在任何路径都能使用（脚本放在声明了全局环境变量的路径）

```
[atguigu@hadoop102 ~]$ echo $PATH

/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/atguigu/.local/bin:/home/atguigu/bin:/opt/module/jdk1.8.0_212/bin
```

（3）脚本实现

（a）在/home/atguigu/bin目录下创建xsync文件

```
[atguigu@hadoop102 opt]$ cd /home/atguigu

[atguigu@hadoop102 ~]$ mkdir bin

[atguigu@hadoop102 ~]$ cd bin

[atguigu@hadoop102 bin]$ vim xsync
```

在该文件中编写如下代码

```sh
#!/bin/bash

 

\#1. 判断参数个数

if [ $# -lt 1 ]

then

  echo Not Enough Arguement!

  exit;

fi

 

\#2. 遍历集群所有机器

for host in hadoop102 hadoop103 hadoop104

do

  echo ==================== $host ====================

  \#3. 遍历所有目录，挨个发送

 

  for file in $@

  do

​    \#4. 判断文件是否存在

​    if [ -e $file ]

​      then

​        \#5. 获取父目录

​        pdir=$(cd -P $(dirname $file); pwd)

 

​        \#6. 获取当前文件的名称

​        fname=$(basename $file)

​        ssh $host "mkdir -p $pdir"

​        rsync -av $pdir/$fname $host:$pdir

​      else

​        echo $file does not exists!

​    fi

  done

done
```

（b）修改脚本 xsync 具有执行权限

```
[atguigu@hadoop102 bin]$ chmod +x xsync
```

（c）测试脚本

```
[atguigu@hadoop102 ~]$ xsync /home/atguigu/bin
```

（d）将脚本复制到/bin中，以便全局调用

```
[atguigu@hadoop102 bin]$ sudo cp xsync /bin/
```

（e）同步环境变量配置（root所有者）

```
[atguigu@hadoop102 ~]$ sudo ./bin/xsync /etc/profile.d/my_env.sh
```

注意：如果用了sudo，那么xsync一定要给它的路径补全。

让环境变量生效

```
[atguigu@hadoop103 bin]$ source /etc/profile

[atguigu@hadoop104 opt]$ source /etc/profile
```



### 3.2.3 SSH无密登录配置

**1****）配置ssh**

（1）基本语法

ssh另一台电脑的IP地址

（2）ssh连接时出现Host key verification failed的解决方法

```
[atguigu@hadoop102 ~]$ ssh hadoop103
```



Ø 如果出现如下内容



```
Are you sure you want to continue connecting (yes/no)? 
```

Ø 输入yes，并回车

（3）退回到hadoop102

```
[atguigu@hadoop103 ~]$ exit
```

**2****）无密钥配置**

（1）免密登录原理

​                                ![image-20230504215602085](D:\Typora\workspace\Unix\脚本分发.assets\image-20230504215602085.png)

（2）生成公钥和私钥

```
[atguigu@hadoop102 .ssh]$ pwd

/home/atguigu/.ssh

 

[atguigu@hadoop102 .ssh]$ ssh-keygen -t rsa
```

然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）

（3）将公钥拷贝到要免密登录的目标机器上

```
[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop102

[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop103

[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop104
```

注意：

还需要在hadoop103上采用atguigu账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。

还需要在hadoop104上采用atguigu账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。

还需要在hadoop102上采用root账号，配置一下无密登录到hadoop102、hadoop103、hadoop104；

**3****）.ssh****文件夹下（~/.ssh****）的文件功能解释**

| known_hosts     | 记录ssh访问过计算机的公钥（public  key） |
| --------------- | ---------------------------------------- |
| id_rsa          | 生成的私钥                               |
| id_rsa.pub      | 生成的公钥                               |
| authorized_keys | 存放授权过的无密登录服务器公钥           |